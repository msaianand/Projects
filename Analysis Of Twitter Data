
import datetime
import tweepy
import json
import time
import emoji
from tweepy.error import TweepError
#set values
access_token = ""
access_token_secret = ""
consumer_key = ""
consumer_secret = ""

auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
# to avoid ratelimit exceed error
api = tweepy.API(auth, wait_on_rate_limit=True)
original_tweet=0
filtered_count=0
reply_count=0
RC=0

#extra tweets 
#i/p poi(person name), Max_Id(crawl tweets until maxid), id_lis(tweet ID list)
def extract_tweets(poi,max_id,id_lis):
    try:
        original_tweet=0
        filtered_count=0
        poi_tweet_file = poi + '-tweets.json'
        end_encountered = 0
        while(end_encountered == 0):
            #print(max_id)
            if max_id == 0:
                #print("Default call")
                cur = tweepy.Cursor(api.user_timeline, screen_name=poi, tweet_mode='extended').items(2000)
            else:
                #print("Max Id call")
                #API call to get tweets
                cur = tweepy.Cursor(api.user_timeline, screen_name=poi,max_id = max_id, tweet_mode='extended').items(2000)
            for tweet in cur:
                 max_id = tweet.id
                 #check original tweet
                 if not hasattr(tweet, 'retweeted_status') and not tweet.in_reply_to_status_id:
                    original_tweet+=1
                    if tweet.created_at < min_date:
                        #print(tweet.created_at)
                        end_encountered = 1
                        break
                    #print(tweet.created_at)
        #             print("before Date check is "+str(tweet.created_at))
        #             print(tweet.created_at < max_date)
        #             print(tweet.created_at > min_date)
                    filtered_count+=1
                    id_lis.append(tweet.id)
        #             print("after Date check is "+str(tweet.created_at))

                    #write data in file
                    with open(poi_tweet_file, 'a+') as f:
                        obj = convertToObj(tweet)
                        #print(obj["tweet_date"])
                        #write in JSON format
                        json.dump(obj, f)
    except TweepError:
        time.sleep(10)
        #crawl next tweet
        extract_tweets(poi,max_id,id_lis)
       
       
#crawl replies for particular tweet
#i/p poi(person name), id_lis(tweet ID list)
def extract_replies(poi,id_list,replies_lis):
    try:
        poi_replies_file = poi + '-replies.json'
        i =0;

        for tweet_id in id_list:
            reply_count = 0
            RC=0
            #print("Getting replies for tweet with id :"+str(tweet_id))
            for tweet in tweepy.Cursor(api.search, q='to:'+poi, since_id=tweet_id, max_id=None,count=1000,tweet_mode='extended').items(10):
              i = i+1;
              if tweet.in_reply_to_status_id == tweet_id:
                #print("Id of the reply is "+str(tweet.id))
                if reply_count <= 20 :
                 RC+=1
                 reply_count+=1
                 replies_lis.append(tweet)
                 #write into file
                 with open(poi_replies_file, 'a+') as f:
                     obj = convertToObj(tweet)
                     #Json format writing   
                     json.dump(obj, f)
                else:
                 break
       
    except TweepError:
        time.sleep(10)
    #crawl for next tweet
        extract_replies(id_list[i:],replies_lis)
 
 #date conversion
def round_to_hour(dt):
    dt_start_of_hour = dt.replace(minute=0, second=0, microsecond=0)
    dt_half_hour = dt.replace(minute=30, second=0, microsecond=0)

    if dt >= dt_half_hour:
        # round up
        dt = dt_start_of_hour + datetime.timedelta(hours=1)
    else:
        # round down
        dt = dt_start_of_hour

    return dt
#getting only the necassary fields
def convertToObj(tweet):
    obj={}
    obj["poi_name"] = tweet.user.screen_name
    obj["poi_id"] = tweet.user.id
    obj["verified"] = tweet.user.verified
    obj["country"] = "America" ## fill these based on the POI ,may be have a map with country as value and poi as key written manually
    obj["replied_to_tweet_id"] = tweet.in_reply_to_status_id_str
    obj["replied_to_user_id"] = tweet.in_reply_to_user_id_str
    if tweet.in_reply_to_user_id:
        obj["reply_text"] = tweet.full_text
    obj["tweet_text"] = tweet.full_text
    obj["tweet_lang"] = tweet.lang
    obj["hashtags"] = tweet.entities["hashtags"]
    obj["mentions"] = tweet.entities["user_mentions"]
    obj["tweet_urls"] = tweet.entities["urls"]
    obj["tweet_emoticons" ] = ''.join(c for c in tweet.full_text if c in emoji.UNICODE_EMOJI)
    obj["tweet_date"] = str(round_to_hour(tweet.created_at))
    return obj





min_date = datetime.datetime(2019, 9, 3)
max_date = datetime.datetime(2019, 9, 8)
poi = 'saianand' #userID
poi_tweet_file = poi + '-tweets.json'
poi_replies_file = poi + '-replies.json'
id_list = []
extract_tweets(poi,0,id_list)
time.sleep(1)
replies_list=[]
extract_replies(poi,id_list,replies_list)

time.sleep(1)
print('Original count', original_tweet)
print('Filtered Replies count', filtered_count)
print('Tot Replies count', RC, len(replies), list)
